RumbleDB is a JSONiq engine that can be used both on your laptop or on a
cluster (e.g. with Amazon EMR or Azure HDInsight).

It runs on top of Apache Spark and must be invoked with spark-submit, both for
local use and for cluster use. Spark must be installed either on your laptop,
or on the cluster.

Usage:
spark-submit <Spark arguments> <path to RumbleDB's jar> <Rumble arguments>

You can RumbleDB on a shell with:
spark-submit rumbledb-1.16.0.jar --shell yes

You can directly inline a query on the command line with:
spark-submit rumbledb-1.16.0.jar --query '1+1'

You can specify an output path with:
spark-submit rumbledb-1.16.0.jar --query '1+1' --output-path my-output.txt

You can specify a query path with:
spark-submit rumbledb-1.16.0.jar --query-path my-query.jq

You can run it as an HTTP server (e.g., for use with a Jupyter notebook) with:
spark-submit rumbledb-1.16.0.jar --server yes --port 9090

RumbleDB also supports Apache Livy for use in Jupyter notebooks, which may be
even more convenient if you are using a cluster.

For local use, you can control the number of cores, as well as allocated
memory, with:
spark-submit --master local[*] rumbledb-1.16.0.jar --shell yes
spark-submit --master local[2] rumbledb-1.16.0.jar --shell yes
spark-submit --master local[*] --driver-memory 10G rumbledb-1.16.0.jar --shell yes

You can use RumbleDB remotely with:
spark-submit --master yarn rumbledb-1.16.0.jar --shell yes

(Although for clusters provided as a service, --master yarn is often implicit
and unnecessary).

For remote use (e.g., logged in on the Spark cluster with ssh), you can set the
number of executors, cores and memory, you can use:
spark-submit --executor-cores 3 --executor-memory 5G rumbledb-1.16.0.jar --shell yes

For remote use, you can also use other file system paths such as S3, HDFS, etc:
spark-submit rumbledb-1.16.0.jar --query-path hdfs://server:port/my-query.jq --output-path hdfs://server:port/my-output.json

More documentation on https://www.rumbledb.org/